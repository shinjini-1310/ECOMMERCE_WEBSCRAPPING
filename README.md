#ECOMMERCE WEBSCRAPPING

Pre-requisites:
1)Python should be installed and its path should be added to environment variable 
2)Requires installation and import of Python packages
3)Webdriver installation based on browser choice
4)A steady Internet connection

SUMMARY
Developed a webscrapper bot to get primary details of desired product from AMAZON, within minimal time, with zero manual intervention. It navigates through all the webpages dedicated to the product, extracts primary titles and prices, and returns the consolidated data in an Excel file.

The entire process is completely automated and swift, thus eliminating unnecessary effort, and helping the user focus on decision-making based on collected data. We can easily scroll through the resultant file and sort/filter product data to make an informed decision based on our personal purchase criteria. 

TECHNOLOGIES USED
Backend: Python, Selenium
Frontend: Shell Scripting,Website - https://www.amazon.in/

ACHIEVEMENTS
1)Simple Setup : No complex requirements except few simple installations.
2)Minimal Execution Time : Since its helpful for beginners to see the step-by-step execution of bot, some sleeping time is allowed between each step. Even then, each run is elapsed within or very close to the expected time.
3)Automatic Snapshotting : Photographic evidences of full screen with personalized titles are automatically captured at each step of each run, ensuring that consolidated proofs are available to support the execution status of each bot run.
4)Elimination of Manual Effort : Absolutely no manual effort is required to obtain the final file and stepwise snapshots. The bot automates the entire event.
5)Authentic Learning Opportunity : We worked with an actual live ecommerce website while building this bot, not a manufactured, simplified website, so an in-depth knowledge of web elements was acquired by extensive research on formulating locators for complex element locations for simulating each manual operation.
6)User Friendly : First time users can easily grasp the workings of the process, since the number of the webpage being currently scrapped, along with primary data of all products in it are simultaneously printed to console

TRIGGER COMMAND:
python [PYTHON_FILENAME_WITH_LOCATION] [SEARCH STRING IN DOUBLE QUOTES]